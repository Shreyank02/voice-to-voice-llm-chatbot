# ğŸ™ï¸ Voice-to-Voice LLM Bot

A real-time conversational assistant that allows users to speak into a microphone, processes the input using speech recognition, generates intelligent responses using a Large Language Model (LLM), and replies back using speech synthesis â€” all within an interactive Streamlit web interface.

---

## ğŸš€ Features

- ğŸ§ **Speech Recognition** using OpenAI's [Whisper](https://github.com/openai/whisper)
- ğŸ§  **LLM-Based Response Generation** using Gemini/OpenAI/your chosen LLM
- ğŸ”Š **Text-to-Speech (TTS)** with `pyttsx3` for local speech playback
- ğŸ’¬ **Conversation Memory** displayed in a real-time chat format
- ğŸŒ **Streamlit UI** for a simple, responsive web interface
- ğŸ›¡ï¸ **Repeat Prevention** to avoid duplicate audio outputs
- âš¡ Optimized for faster processing with reduced latency

---

## ğŸ“ Project Structure

```
voice-to-voice-bot/
â”‚
â”œâ”€â”€ app.py                  # Streamlit UI and app logic
â”œâ”€â”€ main.py                 # Audio recording and Whisper transcription
â”œâ”€â”€ llm.py                  # LLM response generation
â”œâ”€â”€ tts.py                  # Text-to-speech handling
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Documentation
â””â”€â”€ myenv/                  # (Optional) Python virtual environment
```

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/voice-to-voice-bot.git
cd voice-to-voice-bot
```

### 2. Create and Activate a Virtual Environment

```bash
python -m venv myenv
# Activate it:
# Windows
myenv\Scripts\activate
# macOS/Linux
source myenv/bin/activate
```

### 3. Install the Dependencies

```bash
pip install -r requirements.txt
```

### 4. Download Whisper Model (Optional)

In `main.py`, the following line loads the default medium model:

```python
model = whisper.load_model("medium")
```

You can switch to `"base"` or `"small"` for faster performance.

---

## â–¶ï¸ Run the Application

```bash
streamlit run app.py
```

Then, open your browser at `http://localhost:8501` if it doesn't open automatically.

---

## ğŸ“¦ Requirements

Add this to your `requirements.txt` file:

```
streamlit
openai-whisper
sounddevice
scipy
numpy
torch
pyttsx3
```

Install all at once:

```bash
pip install -r requirements.txt
```

---

## âš ï¸ Troubleshooting

- â— On **Windows**, you may need [Microsoft C++ Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) for audio-related packages.
- â— If audio repeats, ensure `speak()` is only called once per response.
- â— Ensure your microphone is functional and allowed in system privacy settings.

---

## ğŸ’¡ To-Do / Ideas

- [x] Add repeat-prevention logic
- [ ] Use GPU for Whisper inference
- [ ] Add multi-language support
- [ ] Add real-time translation feature
- [ ] Convert to mobile or desktop app

---

## ğŸ“ƒ License

MIT License. Feel free to use, share, and modify. Attribution appreciated!

---

## ğŸ™Œ Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper)
- [Streamlit](https://streamlit.io/)
- [Pyttsx3](https://pyttsx3.readthedocs.io/)
